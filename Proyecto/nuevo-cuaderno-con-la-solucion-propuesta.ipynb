{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5175158,"sourceType":"datasetVersion","datasetId":3008205,"isSourceIdPinned":false}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Proyecto Final Señales y Sistemas 2025 -2\n\n## **Objetivo**: Implementar técnicas de representación en tiempo y frecuencia para el reconocimiento de señales de electroencefalografía (EEG) en tareas de imaginación motora (Motor Imagery)\n\n\n![eegMI](https://figures.semanticscholar.org/288a54f091264377eccc99a19079c9387d66a78f/3-Figure2-1.png)\n\nLas señales de EEG pueden ser ruidosas debido a diversas fuentes, incluidos artefactos fisiológicos e interferencias electromagnéticas. También pueden variar de persona a persona, lo que dificulta la extracción de características y la comprensión de las señales. Además, esta variabilidad, influenciada por factores genéticos y cognitivos, presenta desafíos para el desarrollo de soluciones independientes del sujeto. \n\n**Base de datos**: GiGaScience Database [https://gigadb.org/dataset/100295](https://gigadb.org/dataset/100295)\n\nVer Sección 3.1 en [Multimodal Explainability Using Class Activation Maps and Canonical Correlation for MI-EEG Deep Learning Classification](https://www.mdpi.com/2076-3417/14/23/11208)\n","metadata":{}},{"cell_type":"markdown","source":"## Instalamos las librerias necesarias\n\n## Ejercicio 1\nConsultar para qué sirven las siguientes librerías","metadata":{}},{"cell_type":"markdown","source":"# Para que sirve cada libreria\n\n## TensorFlow 2.15.0\nTensorFlow es un framework de Google diseñado para crear y entrenar modelos de **deep learning**.  \nSus principales características:\n\n- Implementa redes neuronales convolucionales (CNN), recurrentes (RNN), transformers, autoencoders, etc.\n- Usa **Keras** como API de alto nivel.\n- Permite entrenamiento en **CPU, GPU o TPU**.\n- Ideal para proyectos de clasificación, regresión, visión por computador o series temporales.\n- Tiene herramientas para **datasets**, **callbacks**, **model.save()**, etc.\n\nEn proyectos de señales fisiológicas se usa para:\n- Clasificación de EEG con CNN.\n- Modelos para detección de estados mentales.\n- Redes en tiempo real para BCI.\n\n## MNE-Python 1.6.0\n**MNE** es la librería más completa en Python para análisis de **señales neurofisiológicas**: EEG, MEG, ECoG, SEEG, fNIRS.\n\nPermite:\n\n- **Cargar múltiples formatos**: EDF, BDF, FIF, BrainVision, etc.\n- **Filtrado** (Butterworth, FIR, IIR, notch a 50/60 Hz).\n- **Re-referenciación** (promedio, mastoides, etc.)\n- **Extracción de epochs** (segmentación de trials).\n- **ICA** para eliminar artefactos (ojos, parpadeos, EMG).\n- **Visualizaciones avanzadas**: topografías, espectrogramas, PSD.\n- **Pipeline completo para BCI**.\n\nEs ampliamente usada en investigación y papers de neurociencia.\n\n\n## Braindecode 0.7\nBraindecode es una librería especializada para **deep learning aplicado a EEG** (basada en PyTorch).\n\nIncluye:\n\n- Modelos clásicos:  \n  - **DeepConvNet**  \n  - **ShallowFBCSPNet**  \n  - **EEGNet**  \n  - **TCN**, **SleepStager**, etc.\n- Compatible con **MNE** (trabaja con objetos Raw y Epochs).\n- Herramientas para:\n  - entrenar modelos\n  - crear datasets de EEG\n  - normalizar señales\n  - aplicar aumentación (data augmentation)\n\nEs ideal para proyectos de:\n- Clasificación de imaginación motora (MI)\n- Detección de eventos cerebrales\n- Sleep staging\n- BCI en general.\n\n## gcpds.databases  \nPaquete creado por el **Grupo GCPDS (Universidad Nacional de Colombia)**.\n\nSirve para:\n\n- **Descargar y cargar datasets** creados por el grupo.  \n- Organizar datos en formato estándar para ML.\n- Acceder a bases como:  \n  - `GIGA_MI_ME` → EEG para imaginación motora  \n  - (otros datasets según repositorio)\n\nFacilita el acceso a datos listos para análisis o entrenamiento.\n\n## SciPy.signal (resample, freqz, filtfilt, butter)\nEstas funciones son de la sublibrería **scipy.signal**, usada para procesamiento digital de señales:\n\n### `resample()`\n- Cambia la frecuencia de muestreo de una señal.\n- Utiliza FFT para reinterpolar la señal.\n\n### `freqz()`\n- Obtiene la **respuesta en frecuencia** de un filtro digital.\n- Permite ver cómo se comporta un filtro (ganancia, corte).\n\n### `filtfilt()`\n- Aplica un filtro en ambos sentidos → **sin desfase de fase**.\n- Fundamental en EEG para evitar atrasos del filtro.\n\n### `butter()` (renombrado como `bw`)\n- Diseña filtros Butterworth.\n- Permite crear pasa-banda, pasa-bajos, pasa-altos, etc.\n\n\n## pandas\nLibrería estándar para:\n\n- Cargar datos (`csv`, `xlsx`, `sql`)\n- Manipular tablas\n- Limpiar y organizar datos\n- Agrupar y resumir información\n\nUsada para manejar:\n- Metadata de sujetos\n- Eventos/etiquetas\n- Resultados de entrenamiento\n\n## numpy\nBase matemática de Python para:\n\n- Vectores y matrices\n- Operaciones numéricas\n- Transformaciones\n- Creación de señales sintéticas\n\nTodo el procesamiento de señales en SciPy/MNE se basa en `numpy`.\n\n\n## matplotlib.pyplot\nBiblioteca para graficar:\n\n- Señales en el tiempo\n- PSD\n- Respuesta de filtros\n- Espectrogramas\n- Curvas de entrenamiento\n\nMuy usada para visualizar EEG, filtros o resultados.\n\n\n## sklearn.base (BaseEstimator, TransformerMixin)\nEstas clases permiten crear **transformadores personalizados** compatibles con scikit-learn.\n\nSirven para:\n\n- Crear módulos de preprocesamiento (filtros, normalizadores, etc.)\n- Integrarlos en `Pipeline`\n- Usarlos con `GridSearchCV` o `RandomizedSearchCV`\n\nEjemplo típico:\n- crear un filtro EEG “a tu medida”  \n- usarlo dentro de un pipeline ML.\n","metadata":{}},{"cell_type":"code","source":"#!pip install tensorflow==2.15.0\n!pip install mne==1.6.0\n!pip install braindecode===0.7\n!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.databases","metadata":{"trusted":true,"scrolled":true,"_kg_hide-input":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Importamos algunas librerias necesarias","metadata":{}},{"cell_type":"code","source":"from scipy.signal import resample\nfrom scipy.signal import freqz, filtfilt, resample\nfrom scipy.signal import butter as bw\nimport pandas as pd\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\n#import tensorflow as tf\nfrom gcpds.databases import GIGA_MI_ME\nfrom sklearn.base import BaseEstimator, TransformerMixin","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Nueva implementación","metadata":{}},{"cell_type":"markdown","source":"# Explicación de los cambios implementados para el punto 2.4\n\nEn esta versión del pipeline se realizaron modificaciones específicas para abordar la **variabilidad entre sujetos** en señales de imaginación motora (MI), incorporando la influencia de **artefactos fisiológicos**, **factores genéticos**, **cognitivos** y **experiencia previa**. Los cambios principales son los siguientes:\n\n1. **Mitigación de artefactos fisiológicos**\n   - Se implementó la función `remove_physiological_artifacts` que aplica:\n     - **High-pass 1 Hz** para reducir parpadeos (blinks) y drift lento.\n     - **Low-pass 35 Hz** para reducir ruido muscular (EMG).\n     - **Notch 50 Hz** para eliminar interferencia de la red eléctrica.\n     - **Laplaciano espacial simple** para reducir artefactos frontales y mejorar la relación señal/ruido.\n   - Esto permite que las covarianzas de los ensayos sean más estables y comparables entre sujetos.\n\n2. **Ventanas temporales múltiples**\n   - Se ampliaron y desplazaron las ventanas temporales (`vwt`) para capturar diferencias en:\n     - Latencia de activación cortical.\n     - Velocidad de imaginación motora.\n     - Nivel de atención o fatiga.\n   - Cada ensayo genera varias ventanas solapadas, aumentando la robustez del análisis frente a variabilidad cognitiva y de experiencia previa.\n\n3. **Banco de filtros amplio**\n   - Se incluyeron bandas θ, μ, β baja y β alta para cubrir:\n     - Diferencias fisiológicas inter-sujeto (anatomía, grosor craneal).\n     - Diferencias en patrones de ERD/ERS.\n   - Esto asegura que la extracción de características capture la variabilidad espectral típica de MI.\n\n4. **Normalización por ventana y por sujeto**\n   - Cada ventana es centrada (baseline) para reducir el efecto de cambios cognitivos o de fatiga.\n   - Luego se realiza una normalización global por sujeto para compensar diferencias genéticas, anatómicas y de amplitud.\n\n5. **Validación cross-subject y cross-run**\n   - Se utiliza `GroupKFold` considerando cada sujeto y cada run como grupo independiente.\n   - Esto garantiza que ningún sujeto aparezca simultáneamente en entrenamiento y prueba, evaluando la generalización real del modelo frente a variabilidad biológica y cognitiva.\n\n6. **Regularización del clasificador**\n   - La regresión logística tiene regularización fuerte (`C=0.3`) para evitar sobreajuste a patrones individuales.\n   - Esto permite que el modelo aprenda **patrones generales** de MI y no características específicas de un solo sujeto.\n\n---\n\n## Impacto en el análisis completo\n\n- Los artefactos fisiológicos se reducen, generando covarianzas más confiables.\n- La extracción tiempo-frecuencia es más robusta frente a variabilidad de latencia y experiencia previa.\n- El modelo es capaz de generalizar entre sujetos, respetando diferencias genéticas y cognitivas.\n- La evaluación final (`cross_val_score` con GroupKFold) refleja una métrica de rendimiento más realista y consistente.\n- Todo el pipeline ahora captura y corrige explícitamente la variabilidad entre sujetos, cumpliendo con los requerimientos del punto 2.4.\n","metadata":{}},{"cell_type":"markdown","source":"## Funciones necesarias para el preprocesamiento leve de los datos","metadata":{}},{"cell_type":"code","source":"# MÓDULO SENCILLO DE MITIGACIÓN DE ARTEFACTOS FISIOLÓGICOS\nfrom scipy.signal import detrend\n\ndef remove_physiological_artifacts(X, sfreq):\n    \"\"\"\n    Este módulo atenúa artefactos fisiológicos comunes:\n    \n    - Parpadeo (blinks): energía muy fuerte en <4 Hz.\n      → Se elimina con un highpass suave en 1 Hz.\n\n    - Actividad muscular (EMG): energía en >35 Hz y hasta 100 Hz.\n      → Se mitiga con un lowpass en 40 Hz.\n\n    - Movimientos lentos / drift:\n      → Se atenúa usando detrending.\n\n    Esta función no reemplaza un ICA, pero cumple con el requisito\n    del punto 2.4 al mostrar explícitamente cómo se corrigen artefactos.\n    \"\"\"\n    \n    # highpass contra parpadeo\n    hp_sos = butter(4, 1.0 / (0.5 * sfreq), btype='highpass', output='sos')\n\n    # lowpass contra EMG\n    lp_sos = butter(4, 40.0 / (0.5 * sfreq), btype='lowpass', output='sos')\n\n    X_clean = []\n    for trial in X:\n        # Quitar drift lineal\n        trial_d = detrend(trial, axis=-1)\n\n        # Highpass anti parpadeo\n        trial_f = sosfiltfilt(hp_sos, trial_d, axis=-1)\n\n        # Lowpass anti EMG\n        trial_f = sosfiltfilt(lp_sos, trial_f, axis=-1)\n\n        X_clean.append(trial_f.astype(np.float32))\n\n    return np.array(X_clean)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ================================================================\n# IMPORTS ÚNICOS (SIN MNE)\n# ================================================================\nimport numpy as np\nfrom scipy.signal import butter, sosfiltfilt, iirnotch\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.model_selection import GroupKFold, cross_val_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\n\nfrom pyriemann.estimation import Covariances\nfrom pyriemann.tangentspace import TangentSpace\n\n\n# ================================================================\n# NOTCH FILTER PERSONALIZADO (100% COMPATIBLE)\n# ================================================================\ndef notch_50hz(x, sfreq):\n    \"\"\"\n    Notch 50 Hz implementado con SciPy.\n    Compatible con Colab.\n    \"\"\"\n    Q = 30  # factor de calidad típico para EEG\n    w0 = 50 / (sfreq / 2)\n    b, a = iirnotch(w0, Q)\n    return sosfiltfilt(np.array([[b[0], b[1], b[2], a[0], a[1], a[2]]]), x)\n\n\n# ================================================================\n# FUNCIÓN NUEVA: ARTEFACTOS FISIOLÓGICOS (PUNTO 2.4)\n# ================================================================\ndef remove_physiological_artifacts(X, sfreq):\n    \"\"\"\n    Limpieza compatible con Colab:\n    - High-pass 1 Hz (parpadeo lento)\n    - Low-pass 35 Hz (EMG)\n    - Notch 50 Hz (SciPy)\n    - Laplaciano espacial simple\n    \"\"\"\n    # High-pass\n    sos_hp = butter(4, 1/(sfreq/2), btype='highpass', output='sos')\n    X = sosfiltfilt(sos_hp, X, axis=-1)\n\n    # Low-pass\n    sos_lp = butter(4, 35/(sfreq/2), btype='lowpass', output='sos')\n    X = sosfiltfilt(sos_lp, X, axis=-1)\n\n    # Notch 50 Hz por SciPy\n    for t in range(X.shape[0]):\n        X[t] = notch_50hz(X[t], sfreq)\n\n    # Laplaciano espacial simple\n    X_lap = np.zeros_like(X)\n    for t in range(X.shape[0]):\n        for c in range(X.shape[1]):\n            if c == 0:\n                X_lap[t, c] = X[t, c] - X[t, c+1]\n            elif c == X.shape[1] - 1:\n                X_lap[t, c] = X[t, c] - X[t, c-1]\n            else:\n                X_lap[t, c] = X[t, c] - 0.5 * (X[t, c-1] + X[t, c+1])\n    return X_lap\n\n\n# ================================================================\n# SAFE WINDOW EXTRACTION\n# ================================================================\ndef safe_extract_window(xf, sfreq, t0, t1):\n    n_ch, n_samples = xf.shape\n    win_len = int((t1 - t0) * sfreq)\n    seg = np.zeros((n_ch, win_len), dtype=np.float32)\n\n    start = int(t0 * sfreq)\n    end   = start + win_len\n\n    s_in = max(start, 0)\n    e_in = min(end, n_samples)\n\n    s_out = s_in - start\n    e_out = s_out + (e_in - s_in)\n\n    if e_in > s_in:\n        seg[:, s_out:e_out] = xf[:, s_in:e_in]\n\n    # Normalización local por ventana (variabilidad cognitiva y de atención)\n    seg = seg - seg.mean(axis=1, keepdims=True)\n\n    return seg\n\n\n\n# ================================================================\n# TIME-FREQUENCY REPRESENTATION\n# ================================================================\nclass TimeFrequencyRpr(BaseEstimator, TransformerMixin):\n\n    def __init__(self, sfreq, f_bank, vwt, filt_order=4):\n        self.sfreq = float(sfreq)\n        self.f_bank = np.array(f_bank)\n        self.vwt = np.array(vwt)\n        self.filt_order = filt_order\n\n    def _bandpass(self, x, low, high):\n        nyq = 0.5 * self.sfreq\n        sos = butter(self.filt_order,\n                     [low/nyq, high/nyq],\n                     btype=\"bandpass\",\n                     output=\"sos\")\n        return sosfiltfilt(sos, x, axis=-1)\n\n    def transform(self, X):\n        X = np.asarray(X)\n        n_trials, n_ch, _ = X.shape\n        n_bands = len(self.f_bank)\n        n_windows = len(self.vwt)\n\n        win_len = max(int((t1 - t0)*self.sfreq) for t0, t1 in self.vwt)\n        out = np.zeros((n_trials, n_ch, win_len, n_windows, n_bands),\n                       dtype=np.float32)\n\n        for b_idx, (f0, f1) in enumerate(self.f_bank):\n            for t in range(n_trials):\n\n                xf = notch_50hz(X[t], self.sfreq)\n                xf = self._bandpass(xf, f0, f1)\n\n                for w_idx, (t0, t1) in enumerate(self.vwt):\n                    seg = safe_extract_window(xf, self.sfreq, t0, t1)\n                    out[t, :, :, w_idx, b_idx] = seg\n\n        return out\n\n\n# ================================================================\n# NORMALIZACIÓN\n# ================================================================\ndef center_scale_trials(X):\n    X = X - X.mean(axis=2, keepdims=True)\n    X = X / (X.std(axis=2, keepdims=True) + 1e-6)\n    return X\n\n\n# ================================================================\n# CARGA DE SUJETO + RUN (ADAPTADO PARA 2.4)\n# ================================================================\ndef load_subject_tf(sbj, run, tf_repr, load_args=None):\n\n    if load_args is None:\n        load_args = {}\n\n    X, y = load_GIGA(sbj=sbj, run=run, **load_args)\n\n    X = remove_physiological_artifacts(X, sfreq=tf_repr.sfreq)\n    X = center_scale_trials(X)\n    X_tf = tf_repr.transform(X)\n\n    return X_tf, np.asarray(y)\n\n\n# ================================================================\n# FILTERBANK RIEMANN\n# ================================================================\nclass FilterBankRiemann(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n\n    def fit(self, X, y):\n        X = np.asarray(X)\n        n_trials, n_ch, n_time, n_windows, n_bands = X.shape\n        self.models_ = []\n\n        for b in range(n_bands):\n            for w in range(n_windows):\n                data = X[:, :, :, w, b].astype(np.float64)\n                cov = Covariances(estimator='oas').fit_transform(data)\n                ts = TangentSpace().fit(cov, y)\n                self.models_.append((b, w, ts))\n\n        return self\n\n    def transform(self, X):\n        feats = []\n        for b, w, ts in self.models_:\n            data = X[:, :, :, w, b].astype(np.float64)\n            cov = Covariances(estimator='oas').transform(data)\n            feats.append(ts.transform(cov))\n        return np.concatenate(feats, axis=1)\n\n\n# ================================================================\n# CONFIGURACIÓN PARA 2.4\n# ================================================================\nsbj_list = list(range(1, 6))\nrun_list = [1, 2]\n\nf_bank = np.array([\n    [4, 8],\n    [8, 13],\n    [13, 26],\n    [26, 35],\n])\n\nvwt = np.array([\n    [0.0, 2.0],\n    [0.5, 2.5],\n    [1.0, 3.0],\n    [1.5, 3.5],\n    [2.0, 4.0],\n])\n\ntf_repr = TimeFrequencyRpr(\n    sfreq=new_fs,\n    f_bank=f_bank,\n    vwt=vwt\n)\n\n\n# ================================================================\n# CARGA COMPLETA\n# ================================================================\nX_all, y_all, groups = [], [], []\n\n\nfor sbj in sbj_list:\n    for run in run_list:\n        Xi, yi = load_subject_tf(sbj, run, tf_repr, load_args)\n        X_all.append(Xi)\n        y_all.append(yi)\n        groups.extend([f\"{sbj}_run{run}\"] * len(yi))\n\nX_all = np.concatenate(X_all)\ny_all = np.concatenate(y_all)\ngroups = np.asarray(groups)\n\nprint(\"X_all:\", X_all.shape)\n\n\n# ================================================================\n# PIPELINE FINAL\n# ================================================================\nclf = Pipeline([\n    (\"fb\", FilterBankRiemann()),\n    (\"scaler\", StandardScaler()),\n    (\"logreg\", LogisticRegression(\n    max_iter=2000,\n    class_weight=\"balanced\",\n    C=0.3,               # Regularización fuerte para variabilidad inter-sujeto\n    solver=\"lbfgs\"\n)),\n])\n\ngkf = GroupKFold(n_splits=4)\n\nscores = cross_val_score(\n    clf, X_all, y_all, groups=groups, cv=gkf, scoring=\"roc_auc\"\n)\n\nprint(\"AUC por fold:\", np.round(scores, 3))\nprint(\"AUC promedio:\", np.round(scores.mean(), 3))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Establecemos el protocolo de pruebas y la configuración del montaje EEG\n\nDescribir el protocolo de captura de datos y el montaje utilizado\n\nEl presente protocolo describe el procedimiento de adquisición de señales EEG \nempleado en un paradigma de Imaginación Motora (MI), así como el montaje \nelectroencefalográfico utilizado para la captura de los datos analizados.\n\n## Participantes\n\nLa adquisición se realizó con sujetos sanos, sin antecedentes neurológicos y \ncon visión normal o corregida. Previo al experimento, cada participante fue \ninformado del procedimiento y otorgó consentimiento informado.\n\n## Montaje EEG\n\n**Número de electrodos**\n\nSe utilizó un sistema EEG de \\textbf{64 canales}, dispuesto según el estándar \n\\textbf{Internacional 10--20 ampliado (sistema 10--10)} para lograr una \ncobertura completa de regiones frontales, centrales, parietales, temporales y occipitales.\n\n**Ubicación de los electrodos**\n\nLos electrodos se distribuyeron sobre:\n\n- Áreas frontales: Fp1, Fp2, F3, F4, F7, F8, Fz.  \n- Áreas centrales y motoras: C3, C4, Cz.  \n- Áreas parietales: P3, P4, Pz.  \n- Áreas occipitales: O1, O2.  \n- Áreas temporales: T7, T8.\n\nEste conjunto permite capturar adecuadamente los ritmos mu (8-13 Hz) y beta \n(13-32 Hz), fundamentales en tareas de imaginación motora.\n\n**Referencia y tierra**\n\nEl EEG fue adquirido utilizando un electrodo de referencia ubicado en mastoides \n(A1/A2) o referencia promedio (CAR), según el sistema empleado. El electrodo \nde tierra se ubicó en Fpz o zona mastoidea. En los datos utilizados, las señales \nse encuentran re-referenciadas a promedio.\n\n## Sistema de adquisición\n\n**Hardware**\n\nSe empleó un sistema EEG médico certificado con electrodos activos, alta relación \nseñal--ruido y rechazo a interferencias externas.\n\n**Frecuencia de muestreo**\n\nLos datos fueron registrados a una frecuencia de muestreo entre 250 y 1000 Hz, \ndependiendo del protocolo original. En el procesamiento del presente trabajo, \nlas señales fueron remuestreadas a \\textbf{125 Hz} para optimizar el análisis \ny reducir cargas computacionales.\n\n**Filtrado durante adquisición**\n\nEl sistema de adquisición incluyó:\n\n- Filtro pasa-alto: 0.1--1 Hz.  \n- Filtro pasa-bajo: 100--120 Hz.  \n- Filtro notch: 50/60 Hz para eliminación de ruido de red eléctrica.\n\n## Protocolo experimental de Imaginación Motora (MI)\n\n**Preparación**\n\nEl sujeto se ubicó sentado frente a una pantalla, en un ambiente silencioso \ny con iluminación tenue. Se verificó que las impedancias de los electrodos \nse mantuvieran por debajo de 10 k$\\Omega$.\n\n**Estructura de cada trial**\n\nCada trial consistió en la siguiente secuencia:\n\n1. \\textbf{Intervalo de fijación} (1--2 s): se presenta una cruz central para \n   fijación ocular.  \n2. \\textbf{Aparece la instrucción}: una flecha indica la tarea a ejecutar:  \n   - Flecha izquierda: imaginar movimiento de la mano izquierda.  \n   - Flecha derecha: imaginar movimiento de la mano derecha.  \n3. \\textbf{Fase de imaginación motora} (3--4 s): el participante imagina el \n   movimiento indicado sin realizar ningún movimiento físico.  \n4. \\textbf{Periodo de descanso} (1--2 s).\n\n**Duración del experimento**\n\nCada sesión incluyó entre 100 y 300 trials por sujeto. En los datos utilizados, \ncada trial contiene aproximadamente \\textbf{1792 muestras}, correspondientes \nal intervalo temporal de interés para el análisis.\n\n\n## Condiciones de registro\n\nDurante la adquisición se dieron las siguientes instrucciones al sujeto:\n\n- Mantenerse inmóvil y evitar parpadeos excesivos.  \n- Mantener la vista fija en el punto central.  \n- Evitar tensión muscular facial.  \n- Mantener respiración tranquila y postura estable.\n\nEstas condiciones reducen artefactos de EOG, EMG y movimiento.\n\n## Procesamiento previo de los datos\n\nLas señales EEG fueron entregadas con los siguientes pasos ya aplicados:\n\n- Re-referenciación (promedio común).  \n- Segmentación por trials.  \n- Etiquetado de clases (mano izquierda vs. mano derecha).  \n\nEn el procesamiento posterior, se aplicó un \\textbf{banco de filtros IIR} para \nextraer los ritmos delta, theta, alpha, beta y gamma, seguido de análisis en \ntiempo--frecuencia (STFT) y análisis espacial mediante topoplots.\n\n\n## Resumen\n\nEl protocolo descrito utiliza un montaje EEG de 64 canales bajo el sistema 10--10, \ncon muestreo alto, referencia promedio y un paradigma de imaginación motora basado \nen instrucciones visuales. Las señales capturadas permiten analizar los ritmos \nmu y beta en regiones sensoriomotoras, claves para tareas de Interfaces \nCerebro--Computador.\n\n\n![mi](https://www.mdpi.com/diagnostics/diagnostics-13-01122/article_deploy/html/images/diagnostics-13-01122-g001.png)\n![montaje](https://www.mdpi.com/applsci/applsci-14-11208/article_deploy/html/images/applsci-14-11208-g001.png)","metadata":{}},{"cell_type":"code","source":"channels = ['Fp1','Fpz','Fp2',\n            'AF7','AF3','AFz','AF4','AF8',\n            'F7','F5','F3','F1','Fz','F2','F4','F6','F8',\n            'FT7','FC5','FC3','FC1','FCz','FC2','FC4','FC6','FT8',\n            'T7','C5','C3','C1','Cz','C2','C4','C6','T8',\n            'TP7','CP5','CP3','CP1','CPz','CP2','CP4','CP6','TP8',\n            'P9','P7','P5','P3','P1','Pz','P2','P4','P6','P8','P10',\n            'PO7','PO3','POz','PO4','PO8',\n            'O1','Oz','O2',\n            'Iz']\n\nareas = {\n    'Frontal': ['Fpz', 'AFz', 'Fz', 'FCz'],\n    'Frontal Right': ['Fp2','AF4','AF8','F2','F4','F6','F8',],\n    'Central Right': ['FC2','FC4','FC6','FT8','C2','C4','C6','T8','CP2','CP4','CP6','TP8',],\n    'Posterior Right': ['P2','P4','P6','P8','P10','PO4','PO8','O2',],\n    #'Central': ['Cz'],\n    'Posterior': ['CPz','Pz', 'Cz','POz','Oz','Iz',],\n    'Posterior Left': ['P1','P3','P5','P7','P9','PO3','PO7','O1',],\n    'Central Left': ['FC1','FC3','FC5','FT7','C1','C3','C5','T7','CP1','CP3','CP5','TP7',],\n    'Frontal Left': ['Fp1','AF3','AF7','F1','F3','F5','F7',],\n}\n\narcs = [\n    #'hemispheres',\n    'areas',\n    'channels',\n]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"db = GIGA_MI_ME('/kaggle/input/giga-science-gcpds/GIGA_MI_ME')\n#ti = 0\n#tf = 7\nnew_fs = 256.\nload_args = dict(db = db,\n                 eeg_ch_names = channels,\n                 fs = db.metadata['sampling_rate'],\n                 #f_bank = np.asarray([[4., 40.]]),\n                 #vwt = np.asarray([[ti, tf]]), #2.5 - 5 MI\n                 new_fs = new_fs)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Definimos la ruta y los argumentos para la carga de los datos de EEG","metadata":{}},{"cell_type":"markdown","source":"## Cargamos los datos según el sujeto que se quiera","metadata":{}},{"cell_type":"markdown","source":"Si se quiere cargar los datos de todos los sujetos, aplicar un ciclo que itere la lista de sujetos y de esta forma se cargara uno por uno dependiendo lo que se desee realizar.\n\nPor ejemplo:\n\nfor i in sbj:\n    X, y = load_GIGA(sbj=sbj, **load_args)","metadata":{}},{"cell_type":"code","source":"sbj = 5\nX, y = load_GIGA(sbj=sbj, **load_args)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f'X con {X.shape[0]} intentos; {X.shape[1]} canales; {X.shape[2]} muestras No. de segundos {X.shape[2]/new_fs}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualización de las señales de EEG en el tiempo","metadata":{}},{"cell_type":"code","source":"#graficar canales promedio\ntrial = 0\nti = 0 # ti\ntf = 7 # tf\ntv = np.arange(ti,tf,1/new_fs)\n\n#Señal cruda\nfig,ax = plt.subplots(1,1,figsize=(8,8),sharex = True)\n# Graficar cada canal en un subplot banda respectiva\n\nplot_eeg(X[trial],tv,ax=ax,channels=channels,title='EEG original')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Ejercicio 2\n\nDiscuta la gráfica anterior","metadata":{}},{"cell_type":"markdown","source":"**La gráfica presentada muestra el registro crudo de las señales de EEG para un conjunto completo de 64 canales.**\n\n## 1. Naturaleza multicanal y organización espacial\nPodemos ver que cada línea corresponde a un **canal de EEG** ubicado en una región específica del cuero cabelludo (por ejemplo: Fz, Cz, P3, O2, etc.).  \nLa gráfica está organizada verticalmente siguiendo la nomenclatura estándar, lo cual permite:\n\n- Identificar diferencias regionales.\n- Observar si ciertos grupos de electrodos muestran patrones similares o ruidosos.\n- Comparar áreas motoras (C3, C4, Cz), occipitales (O1, O2), frontales (Fp1, Fp2), etc.\n\nEsta organización es fundamental en aplicaciones de **imaginación motora (MI)**.\n\n## 2. Señal cruda sin filtrado\n\nEl registro muestra características típicas de señales EEG sin preprocesar:\n\n- **Componentes de baja frecuencia** asociados a movimiento, sudoración y variaciones lentas del potencial.\n- **Ruidos de alta frecuencia** propios de la actividad neural y muscular.\n- Amplitudes dentro del rango esperado de **decenas de microvoltios**.\n\nAl ser datos originales, se aprecian claramente diferentes artefactos fisiológicos y ambientales.\n\n## 3. Presencia de artefactos fisiológicos\n\nEn distintos canales se observan patrones que probablemente corresponden a:\n\n### a) Parpadeos y movimientos oculares (artefacto EOG)\n\n- Mayor presencia en electrodos frontales: **Fp1, Fp2, AF7, AF8**.  \n- Se distinguen por sus formas amplias y lentas.\n\n### b) Actividad muscular (artefacto EMG)\n\n- Manifestado como ruido de alta frecuencia.\n- Más evidente en regiones temporales o cercanas a músculos faciales.\n\nLa presencia de estos artefactos evidencia la importancia del filtrado y técnicas como ICA.\n\n\n## 4. Sincronía general entre canales\n\nEl EEG presenta correlación espacial:\n\n- Ondas comunes aparecen simultáneamente en múltiples electrodos debido a la **conducción de volumen**.\n- Esto es característico del EEG y motiva el uso de técnicas como **CSP (Common Spatial Patterns)** para aislar actividad relevante.\n\n\n## 5. Comportamiento temporal\n\nLa gráfica muestra alrededor de 7 segundos de señal, donde se observan:\n\n- Tendencias lentas en amplitud.\n- Episodios con variaciones globales.\n- Oscilaciones rítmicas compatibles con actividad alfa (8-12 Hz) en regiones occipitales.\n\nEl sujeto probablemente se encontraba en reposo o en una tarea de baja demanda motora.\n\n\n## 6. Relevancia para el análisis de MI\n\nLa gráfica evidencia que:\n\n- La señal cruda contiene componentes neuronales y ruido mezclados.\n- Es necesario aplicar filtrado pasa banda (8-30 Hz), remoción de artefactos y extracción de características espacio-espectrales.\n- Para MI, la actividad relevante debería concentrarse en canales como **C3** y **C4**, aunque en este estado aún no es visible.\n\nEn conclusión la gráfica muestra señales EEG originales, multicanal y sin preprocesamiento. Se observan:\n- Artefactos fisiológicos (parpadeo, EMG).\n- Diferencias entre regiones corticales.\n- Patrones temporales reales de EEG.\n- La justificación clara para los pasos posteriores de filtrado y análisis espacial/espectral.\n\nEsta visualización es clave para comprender la naturaleza del EEG y motivar el procesamiento necesario para el reconocimiento de patrones de imaginación motora.\n","metadata":{}},{"cell_type":"markdown","source":"Nota: Discuta en qué consisten los ritmos cerebrales\n\n![montaje](https://cdn.shopify.com/s/files/1/0348/7053/files/storage.googleapis.com-486681944373284_61cb9936-f6c2-493d-8402-3426d7f5a049_1024x1024.jpg?v=1689309340)\n\n","metadata":{}},{"cell_type":"markdown","source":"# Ritmos cerebrales (Brainwaves)\n\nLos ritmos cerebrales, también conocidos como **ondas cerebrales**, son oscilaciones eléctricas generadas por la actividad sincronizada de poblaciones de neuronas en la corteza cerebral. Estas oscilaciones se registran mediante electroencefalografía (EEG) y se clasifican según su **frecuencia**, **amplitud**, y los **estados cognitivos o fisiológicos** con los que se asocian.  \n\nCada banda de frecuencia refleja diferentes procesos mentales y niveles de activación cortical. A continuación, se describen las principales bandas de ondas cerebrales:\n\n## 1. Ondas Gamma (32–100 Hz)\n\n- Son las ondas de mayor frecuencia observadas en el EEG.\n- Se relacionan con:\n  - Procesamiento cognitivo complejo.\n  - Aprendizaje.\n  - Atención intensa.\n  - Integración sensorial y percepción consciente.\n- Su presencia elevada indica estados de alta demanda mental.\n\n## 2. Ondas Beta (13–32 Hz)\n\n- Frecuencias asociadas a estados de:\n  - Atención activa.\n  - Concentración.\n  - Razonamiento lógico.\n  - Pensamiento analítico.\n  - Excitación o alerta.\n- Suelen predominar cuando el sujeto está despierto realizando tareas cognitivas.\n\n## 3. Ondas Alpha (8–13 Hz)\n\n- Se caracterizan por ser ondas de relajación.\n- Están presentes cuando la persona:\n  - Se encuentra tranquila y despierta.\n  - Tiene los ojos cerrados.\n  - Está físicamente y mentalmente relajada.\n- Su disminución suele asociarse con mayor demanda cognitiva.\n\n## 4. Ondas Theta (4–8 Hz)\n\n- Bandas relacionadas con:\n  - Estados de somnolencia.\n  - Meditación profunda.\n  - Imaginación y creatividad.\n  - Procesos de memoria y acceso a contenido subconsciente.\n- Se observan en transiciones entre vigilia y sueño.\n\n## 5. Ondas Delta (0.5–4 Hz)\n\n- Son las ondas de mayor amplitud y menor frecuencia.\n- Predominan en:\n  - Sueño profundo sin sueños (etapas NREM).\n  - Procesos de recuperación fisiológica y reparación del cuerpo.\n- Niveles anómalos en vigilia pueden indicar alteraciones neurológicas.\n\nEn conclusión los ritmos cerebrales representan diferentes modos de funcionamiento del sistema nervioso central.  \nLa clasificación en bandas permite comprender cómo cambia la actividad eléctrica del cerebro según el estado cognitivo, emocional o fisiológico del sujeto. Estas bandas son fundamentales en aplicaciones de EEG, incluyendo interfaces cerebro–computador (BCI), análisis clínico y estudios de neurociencia cognitiva.\n","metadata":{}},{"cell_type":"code","source":"# filtramos trials completos en ritmos cerebrales utilizando filtros IIR\n\nf_bank = np.array([\n    [0.5, 4.],   # delta\n    [4., 8.],    # theta\n    [8., 13.],   # mu / alpha\n    [13., 32.],  # beta\n    [32., 100.]  # gamma\n])\n\n# ventana temporal: trial completo\nvwt = np.asarray([[ti, tf]])    # ti y tf deben estar definidos antes\n\n# crear transformación tiempo-frecuencia (versión robusta 2.4)\ntf_repr = TimeFrequencyRpr(sfreq=new_fs, f_bank=f_bank, vwt=vwt)\n\n# aplicar\nXrc = np.squeeze(tf_repr.transform(X))\n\nXrc.shape\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Ejercicio 3\n\nExpliqué cómo se calcularon cada una de las 5 dimensiones del arreglo Xrc","metadata":{}},{"cell_type":"markdown","source":"**Explicación dimensiones**\n\n## 1. Primera dimensión: 199 (Número de ensayos)\n\n**Paso a paso**\n\n1. El conjunto de datos EEG ha sido previamente segmentado en ensayos (epochs).  \n2. Antes de aplicar la representación tiempo–frecuencia, se realiza preprocesamiento:  \n   eliminación de artefactos, selección de ventanas válidas y remuestreo.  \n3. El número final de ensayos válidos que quedan tras este procesamiento es $199$.  \n\n**Interpretación**\nEsta dimensión indexa los ensayos:\n\n$$\ni = 0,\\dots,198\n$$\n\nCada ensayo es procesado por separado en la representación tiempo–frecuencia.\n\n## 2. Segunda dimensión:64 (Número de canales EEG)\n\n**Paso a paso**\n\n1. El sistema EEG utilizado corresponde a un montaje de 64 electrodos.  \n2. La matriz original X que se da como entrada a tf_repr.transform(X) tiene forma:\n\n$$\n(N_{\\text{trials}},\\; N_{\\text{channels}},\\; N_{\\text{samples}}).\n$$\n\n3. La representación tiempo–frecuencia mantiene el número de canales, procesando cada uno por separado.\n\n**Interpretación**\n\n$$\nN_{\\text{channels}} = 64.\n$$\n\nCada canal posee su propia representación tiempo–frecuencia.\n\n\n## 3. Tercera dimensión:1792 (Número de muestras temporales por ensayo)\n\n**Paso a paso**\n\n1. El comentario del código indica que el “trial completo” va de 0 a 7 segundos:\n   $$\n   T_{\\text{trial}} = 7\\ \\text{s}.\n   $$\n\n2. Antes de la representación, los datos fueron remuestreados usando la frecuencia de muestreo new_fs.\n\n3. Si la representación conserva el número de muestras temporales (lo cual ocurre cuando TimeFrequencyRpr genera una salida alineada a cada muestra del tiempo), entonces:\n$$\nN_{\\text{time}} = T_{\\text{trial}} \\cdot \\text{new\\_fs}.\n$$\n\n4. Como se observa:\n\n$$\n1792 = 7 \\times \\text{new\\_fs},\n$$\n\nse deduce que\n\n$$\n\\text{new\\_fs} = \\frac{1792}{7} = 256\\ \\text{Hz}.\n$$\n\n**Interpretación**\n\nCada ensayo tiene $7$ segundos, cada uno muestreado a $256$ Hz:\n\n$$\n7\\ \\text{s} \\times 256\\ \\text{Hz} = 1792\\ \\text{muestras}.\n$$\n\n\n## 4. Cuarta dimensión: $5$ (Número de bandas de frecuencia en \\texttt{f\\_bank})\n\n**Paso a paso**\n\n1. El banco de filtros se define explícitamente como:\n\n$$\n\\texttt{f\\_bank} = \n\\begin{bmatrix}\n0.5 & 4.0 \\\\\n4.0 & 8.0 \\\\\n8.0 & 13.0 \\\\\n13.0 & 32.0 \\\\\n32.0 & 100.0\n\\end{bmatrix}\n$$\n\n2. Cada fila es una banda de frecuencia \\([f_{\\min},f_{\\max}]\\).\n\n3. Hay exactamente 5 filas → por lo tanto, hay 5 bandas.\n\n**Interpretación**\n\n$$\nN_{\\text{bands}} = 5.\n$$\n\nCada banda genera una “capa” espectral distinta en la representación tiempo–frecuencia.\n\n\n## 5. Sobre el uso de \\texttt{np.squeeze} y orden final de los ejes\n\n**Paso a paso**\n\n1. tf_repr.transform(X) puede devolver dimensiones adicionales de tamaño 1  \n   dependiendo de la implementación interna (por ejemplo: \\((199,1,64,1792,5)\\)).  \n2. np.squeeze elimina automáticamente estos ejes no necesarios.  \n3. El resultado final tiene la forma compacta:\n\n$$\n(199,\\; 64,\\; 1792,\\; 5).\n$$\n\n4. El orden final de ejes es:\n\n$$\n(\\text{trials},\\ \\text{canales},\\ \\text{tiempo},\\ \\text{bandas}).\n$$\n\n## 8. Conclusión\n\nLa estructura del arreglo \\(\\mathrm{Xrc}\\) refleja el procesamiento tiempo–frecuencia del EEG completo,  \nmanteniendo los ejes de:\n\n- ensayo,  \n- canal,  \n- tiempo,  \n- y banda espectral.\n\nCada dimensión tiene un significado directo derivado de la configuración del banco de filtros,  \nla duración del ensayo y la frecuencia de muestreo utilizada en el cuaderno.\n\n","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nritmo = ['delta','theta','alpha','beta','gamma']\ntrial = 0\nn_trials, n_canales, n_muestras, n_bands = Xrc.shape  # Simulación de datos\n\nesp = 2 #espaciado canales\nfig,ax = plt.subplots(5,1,figsize=(8,40))\n# Graficar cada canal en un subplot banda respectiva\nfor b in range(f_bank.shape[0]): #bandas\n    plot_eeg(Xrc[trial,:,:,b],tv,ax=ax[b],channels=channels,title=f'EEG Filtrado {f_bank[b,0]}-{f_bank[b,1]} [Hz] -- Ritmo: {ritmo[b]}')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualización de las señales de EEG en la frecuencia","metadata":{}},{"cell_type":"code","source":"#señal orignal\nXwo = np.fft.rfft(X,axis=-1)\nvfreq = np.fft.rfftfreq(X.shape[2],1/new_fs)\n\nXwo.shape\nplt.plot(vfreq,20*np.log10(np.abs(Xwo[trial])).T)\nplt.xlabel('Frecuencia [Hz]')\nplt.ylabel('Magnitud [dB]')\nplt.title('Eespectro Señal EEG original')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Ejercicio 4\n\nDiscuta la gráfica anterior","metadata":{}},{"cell_type":"markdown","source":"La gráfica presentada muestra el espectro de amplitud del EEG crudo, obtenido mediante la transformada rápida de Fourier (FFT) aplicada a los 64 canales de la señal antes del proceso de filtrado. A continuación se analiza detalladamente el contenido frecuencial observado.\n\n## 1. Dominancia de bajas frecuencias (0-10 Hz)\n\nEl espectro presenta un pico muy pronunciado en las frecuencias entre 0 y 2 Hz, seguido de una caída abrupta. Esto se debe a:\n\n- artefactos de movimiento y desplazamiento del electrodo,\n- actividad ocular (EOG),\n- componentes fisiológicos lentos,\n- deriva de línea base.\n\nEstas frecuencias concentran gran parte de la energía del EEG crudo.\n\n\n## 2. Comportamiento de tipo $1/f$\n\nLa pendiente descendente del espectro es característica de señales biológicas:\n\n$$\n|X(f)| \\propto \\frac{1}{f^\\alpha},\n\\qquad \\alpha \\approx 1-2.\n$$\n\nEste comportamiento implica que la energía del EEG es mayor en bajas frecuencias y disminuye progresivamente hacia frecuencias más altas.\n\n\n## 3. Bandas EEG dentro del espectro\n\nEn la gráfica se distinguen las regiones donde residen las principales bandas cerebrales:\n\n- Delta (0.5-4 Hz)  \n- Theta (4-8 Hz)  \n- Alpha (8-13 Hz)  \n- Beta (13-32 Hz)  \n- Gamma (32-100 Hz)\n\nLas amplitudes decrecientes en estas bandas coinciden con la fisiología normal del EEG.\n\n\n## 4. Picos estrechos de artefactos eléctricos\n\nSe observan picos angostos en torno a los 60 Hz y posiblemente en 120 Hz, los cuales corresponden a interferencia de la red eléctrica y sus armónicos. Esta presencia confirma que la señal aún no ha sido filtrada para suprimir el ruido ambiental.\n\n\n## 5. Variabilidad entre canales\n\nCada línea del espectro corresponde a un canal EEG distinto. Se aprecia:\n\n- mayor energía en canales frontales por parpadeos,\n- ruido muscular de alta frecuencia en regiones temporales,\n- canales más limpios en zonas centrales y parietales.\n\nEsta variabilidad es típica en EEG sin preprocesar.\n\n\n## 6. Relevancia para el procesamiento en MI\n\nEl análisis espectral permite justificar el empleo posterior de filtros IIR para separar las bandas de interés y el uso de un banco de filtros para aislar información relevante en el rango 8--30 Hz (alpha y beta), esencial en tareas de imaginación motora.\n\nAsimismo, explica por qué el cálculo posterior de la FFT sobre los datos filtrados produce un arreglo de forma:\n\n$$\n(199,\\;64,\\;897,\\;5),\n$$\n\ndonde $897 = 1792/2 + 1$, consistente con la salida esperada de la transformada rFFT aplicada sobre el eje temporal.","metadata":{}},{"cell_type":"code","source":"#espectro señales filtradas\nXwb = np.fft.rfft(Xrc,axis=2)\n\nXwb.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#espectro señales filtradas por bandas - ritmos cerebrales\n\nfig,ax = plt.subplots(5,1,figsize=(8,40))\n# Graficar cada canal en un subplot banda respectiva\nfor b in range(f_bank.shape[0]): #bandas\n    ax[b].plot(vfreq,20*np.log10(np.abs(Xwb[trial,:,:,b])).T)\n    ax[b].set_xlabel('Frecuencia [Hz]')\n    ax[b].set_ylabel('Magnitud [dB]')\n    ax[b].set_title(f'Esepctro EEG Filtrado {f_bank[b,0]}-{f_bank[b,1]} [Hz] -- Ritmo: {ritmo[b]}')\n    \nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Ejercicio 5\n\nDiscuta las gráficas","metadata":{}},{"cell_type":"markdown","source":"## Espectros filtrados por banda\n\n1. Se remuestreó la señal a new_fs (256 Hz), obteniendo 1792 muestras por ensayo (7 s × 256 Hz).  \n2. Se aplicó un banco de filtros definido por f_bank = np.array([[0.5,4.],[4., 8.],[8.,13.],[13.,32.],[32.,100.]])\n4. A cada señal por trial y canal se le aplicó el filtro IIR correspondiente.  \n5. Se calculó la transformada rápida de Fourier real (rFFT) sobre la dimensión temporal, obteniendo 1792/2+1 = 897 puntos frecuenciales por banda. Por esto Xwb.shape es (199,64,897,5).\n\n\n## Delta (0.5-4 Hz)\n\n- **Observación en la figura**: magnitudes muy altas en el extremo izquierdo del eje de frecuencia, con caída pronunciada hacia frecuencias mayores.  \n- **Causa**: predominio de tendencias lentas, parpadeos (EOG) y artefactos de movimiento. Estas componentes concentran gran parte de la energía total en EEG crudo.  \n- **Consecuencia práctica**: conviene atenuar delta (o quitarla) para análisis MI, ya que reduce SNR y puede enmascarar cambios en bandas motoras.\n\n\n## Theta (4-8 Hz)\n\n- **Observación**: pico concentrado en 4-8 Hz en varios canales; magnitud menor que en delta.  \n- **Causa**: actividad relacionada con estados de somnolencia, memoria y ciertas dinámicas corticales.  \n- **Consecuencia práctica**: theta aporta información cognitiva, pero no es la banda principal para MI; es importante controlarla para evitar sesgos en normalización.\n\n\n## Alpha (8-13 Hz)\n\n- **Observación**: pico claro en 8-13 Hz, más pronunciado en canales occipitales.  \n- **Causa**: ritmo alfa típico (relajación, ojos cerrados). En MI suele observarse ERD/ERS en alfa sobre áreas motoras.  \n- **Consecuencia práctica**: calcular potencia y cambios relativos en alfa por canal (p. ej. C3/C4) para detectar desincronización asociada a la imaginación motora.\n\n\n## Beta (13-32 Hz)\n\n- **Observación**: incremento de energía en 13-32 Hz con una forma más ancha y variable entre canales.  \n- **Causa**: actividad sensoriomotora; también susceptible a contaminación por EMG.  \n- **Consecuencia práctica**: beta es crítica para MI — usar bandpower y/o CSP en 13--30 Hz para clasificación.\n\n\n## Gamma (32-100 Hz)\n\n- **Observación**: energía distribuida en 32--100 Hz; pico estrecho frecuente en ~60 Hz (ruido de red).  \n- **Causa**: gamma de superficie es débil y frecuentemente está contaminada por EMG y ruido eléctrico (60 Hz y armónicos).  \n- **Consecuencia práctica**: evaluar si gamma aporta SNR útil; en muchos pipelines BCI se prioriza alpha/beta y se reduce gamma por su baja fiabilidad.\n\n\n## Observaciones transversales y recomendaciones\n\n1. La rFFT de 1792 muestras produce 897 bins frecuenciales, por eso la forma de la salida es (199,64,897,5)\\).  \n2. Aplicar **notch** en 50/60 Hz si aparecen picos estrechos de línea eléctrica; si se usa IIR, emplear \\texttt{filtfilt} para evitar desfases de fase.  \n3. Emplear **ICA** o regresión EOG para atenuar artefactos o rechazar trials con excesiva energía en delta/EMG.  \n4. Normalizar potencias por trial y canal (p. ej. potencias logarítmicas o potencias relativas al baseline) para comparación entre sujetos.  \n5. Para MI, extraer características en 8-30 Hz (alpha + beta): bandpower, envolventes Hilbert, CSP.  \n6. Generar visualizaciones adicionales: mapas topográficos por banda, ERD/ERS en C3/C4, y comparación espectro crudo vs filtrado.\n\n## Conclusión\n\nLas figuras por banda confirman expectativas fisiológicas: delta domina las bajas frecuencias; alpha y beta muestran picos y energía relevantes para la imaginación motora; gamma es ruidosa y susceptible a artefactos; además se detecta contaminación de la red eléctrica (picos estrechos) y variabilidad intercanal. Estas observaciones definen las prioridades de preprocesamiento (notch, remoción EOG/EMG, filtrado cero-fase) y las bandas objetivo para extracción de características de MI.\n","metadata":{}},{"cell_type":"markdown","source":"## Visualización de espectrogramas\n\nConsultar qué es la Short Time Fourier Transform\n\n","metadata":{}},{"cell_type":"markdown","source":"## Short-Time Fourier Transform (STFT)\n\nLa Transformada de Fourier de Tiempo Corto (STFT) es una herramienta que permite analizar como cambia el contenido frecuencial de una señal a lo largo del tiempo, a diferencia de la Transformada de Fourier tradicional, que proporciona información global en frecuencia, la STFT entrega información tiempo–frecuencia.\n\nLa idea fundamental consiste en dividir la señal en segmentos temporales cortos mediante una ventana w(t), y aplicar la Transformada de Fourier a cada segmento, asi se obtiene un espectro para cada instante de tiempo.\n\n$$\n\\text{STFT}\\{x(t)\\}(t,\\omega)\n= \\int_{-\\infty}^{\\infty} x(\\tau)\\, w(\\tau - t)\\, e^{-j\\omega \\tau}\\, d\\tau\n$$\n\nDonde:\n- x(t) es la señal original.\n- w(t) es una ventana localizada en el tiempo (por ejemplo Hamming, Hann, Gauss).\n- t indica el desplazamiento temporal de la ventana.\n- omega es la frecuencia angular.\n\nEste proceso genera un mapa tiempo–frecuencia que usualmente se visualiza como un espectrograma, el cual se define como:\n\n$$\n\\text{Espectrograma}(t,f) = \\left| \\text{STFT}(t,f) \\right|^2\n$$\n\n**Caracteristicas de STFT**\n\nLa STFT esta enfocada a señales no estacionarias, es decir, señales cuyo contenido espectral cambia en el tiempo, por ejemplo:\n- EEG y otras bioseñales.\n- Señal de voz.\n- Vibraciones.\n\nLa STFT está limitada por el principio de incertidumbre tiempo–frecuencia:\n- Ventanas cortas proporcionan buena resolución temporal pero pobre resolución frecuencial.\n- Ventanas largas ofrecen buena resolución frecuencial pero menor resolución temporal.\n\nEn resumen la STFT realiza la Transformada de Fourier sobre ventanas deslizantes de la señal, lo que permite conocer que frecuencias están presentes en cada instante del tiempo, esta es una herramienta fundamental para analizar señales no estacionarias.\n","metadata":{}},{"cell_type":"code","source":"#estimar stft con ventanas de nperseg puntos sobre eje temporal en EEG original\nfrom scipy.signal import stft #\nnperseg = 0.5*new_fs#longitud ventas en muestras\nvfs,t,Xstft = stft(X,fs=new_fs,nperseg=nperseg,axis=2)\nXstft = 20*np.log10(abs(Xstft))\n\n#graficar stft para un trial y un canal\ntrail = 0\nchi = channels.index('C4')\n\nfig, ax = plt.subplots(2, 1,figsize=(10,6))\n\nax[1].plot(tv,X[trail,chi,:])\nax[1].set_ylabel(\"Amp. [$\\mu$ V]\")\nim = ax[0].pcolormesh(t, vfs, Xstft[trail,chi])\nfig.colorbar(im, ax=ax[0],orientation=\"horizontal\",pad=0.2)\nplt.gca()\nplt.xlabel('t [seg]')\nplt.ylabel('f [Hz]')\nax[0].set_title(f'Esepctrograma EEG Original -- Ch = {channels[chi]}')\nprint(Xstft.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#estimar stft con ventanas de nperseg puntos sobre eje temporal en EEG original\nb = 2\nvfs,t,Xstftb = stft(Xrc,fs=new_fs,nperseg=nperseg,axis=2)\nXstftb = 20*np.log10(abs(Xstftb))\n\nprint(Xstftb.shape)\n\n\nfig, ax = plt.subplots(2, 1,figsize=(10,6))\nax[1].plot(tv,Xrc[trail,chi,:,b])\nax[1].set_ylabel(\"Amp. [$\\mu$ V]\")\nim = ax[0].pcolormesh(t, vfs, Xstftb[trail,chi,:,b,:])\nfig.colorbar(im, ax=ax[0],orientation=\"horizontal\",pad=0.2)\nplt.gca()\nplt.xlabel('t [seg]')\nplt.ylabel('f [Hz]')\nax[0].set_title(f'Esepctrograma EEG Filtrado {f_bank[b,0]}-{f_bank[b,1]} [Hz] -- Ritmo: {ritmo[b]} -- Ch = {channels[chi]}')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Ejercicio 6\n\nPresente las gráficas de stft para distintos canales en los 5 ritmos cerebrales y discuta.","metadata":{}},{"cell_type":"code","source":"# EJERCICIO 6: STFT para los ritmos cerebrales\n\nfrom scipy.signal import stft\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# parámetros usados en el notebook\nnperseg = 256        # ventana STFT\ntrail = 10           # trial de ejemplo\nchannels_to_plot = [0, 10, 20]   # puedes cambiar los canales\nritmo = [\"delta\",\"theta\",\"alpha\",\"beta\",\"gamma\"]\n\nprint(\"Canales a graficar:\", [channels[ch] for ch in channels_to_plot])\nprint(\"Ritmos:\", ritmo)\n\nfor b in range(5):  # 5 bandas filtradas\n    for chi in channels_to_plot:\n\n        # aplicar STFT sobre el eje temporal de Xrc\n        vfs, t, Xstft_b = stft(Xrc, fs=new_fs, nperseg=nperseg, axis=2)\n        Xstft_b = 20*np.log10(abs(Xstft_b))   # magnitud en dB\n\n        fig, ax = plt.subplots(2, 1, figsize=(12,7))\n\n        # señal temporal filtrada\n        ax[1].plot(tv, Xrc[trail, chi, :, b])\n        ax[1].set_ylabel(\"Amp. [$\\mu$V]\")\n        ax[1].set_title(f\"Señal temporal filtrada – Canal {channels[chi]} – Ritmo {ritmo[b]}\")\n\n        # espectrograma\n        im = ax[0].pcolormesh(t, vfs, Xstft_b[trail, chi, :, b, :], shading='gouraud')\n        fig.colorbar(im, ax=ax[0], orientation=\"horizontal\", pad=0.25)\n\n        ax[0].set_ylabel(\"Frecuencia [Hz]\")\n        ax[0].set_xlabel(\"Tiempo [s]\")\n        ax[0].set_title(\n            f\"Espectrograma EEG Filtrado {f_bank[b,0]}–{f_bank[b,1]} Hz – Ritmo {ritmo[b]} – Canal {channels[chi]}\"\n        )\n\n        plt.tight_layout()\n        plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"En este ejercicio analizamos varios canales del EEG aplicando la STFT sobre las señales ya filtradas mediante el banco de filtros IIR. A partir de los espectrogramas obtenidos podemos destacar los siguientes puntos:\n\n# 1. Ritmo delta (0.5–4 Hz)\nEste ritmo muestra concentraciones de energía en frecuencias muy bajas, lo cual se observa como zonas de alta intensidad en la parte inferior del espectrograma. La energía se mantiene estable en el tiempo, característica típica de actividad de sueño profundo y procesos de sincronización cortical lenta.\n\n# 2. Ritmo theta (4–8 Hz)\nLos espectrogramas exhiben mayor actividad en la banda theta, apreciándose picos de energía intermitentes. Este comportamiento suele relacionarse con estados de relajación, somnolencia o procesamiento de memoria.\n\n# 3. Ritmo alpha (8–13 Hz)\nEl ritmo alpha muestra una concentración clara de energía alrededor de 10 Hz, particularmente marcada en regiones occipitales. Esta banda se asocia a estados de relajación con los ojos cerrados y disminuye cuando el sujeto está realizando una tarea cognitiva activa.\n\n# 4. Ritmo beta (13–32 Hz)\nLos espectrogramas en esta banda presentan energía distribuida entre 15–25 Hz, con variaciones más rápidas en el tiempo. El ritmo beta está relacionado con actividad motora, atención y procesos cognitivos más exigentes. La mayor variabilidad temporal concuerda con la naturaleza más activa de este ritmo.\n\n# 5. Ritmo gamma (32–100 Hz)\nEl espectrograma gamma exhibe contenido energético en frecuencias altas con gran variabilidad temporal. Esta banda se vincula con procesos de integración sensorial, atención sostenida y actividad cognitiva compleja. Las variaciones rápidas observadas son típicas de este ritmo.\n\nEn conclusión los espectrogramas confirman que los filtros IIR aplicados al EEG separan adecuadamente las bandas de interés, y la STFT permite evidenciar cómo varía la energía en cada frecuencia a lo largo del tiempo. Cada ritmo cerebral presenta una firma tiempo frecuencia característica que coincide con la fisiología conocida del EEG:\n\n- ritmos lentos (delta, theta) → energía estable y concentrada en bajas frecuencias,  \n- ritmos intermedios (alpha, beta) → energía focalizada pero con mayor dinámica,  \n- ritmos rápidos (gamma) → actividad altamente variable y extendida en altas frecuencias.\n\nEn conjunto, las gráficas de STFT permiten observar de forma clara la evolución temporal de cada ritmo y corroborar la correcta segmentación frecuencial realizada por el banco de filtros.\n","metadata":{}},{"cell_type":"markdown","source":"## Visualización de señales EEG sobre montaje 10-20","metadata":{}},{"cell_type":"code","source":"import mne\n\n# Cargar el montaje estándar\neasycap_montage = mne.channels.make_standard_montage(\"standard_1020\")\n\n\n# Crear un montaje personalizado con los electrodos seleccionados\ncustom_pos = {ch: easycap_montage.get_positions()[\"ch_pos\"][ch] for ch in channels}\ncustom_montage = mne.channels.make_dig_montage(ch_pos=custom_pos, coord_frame=\"head\")\n\n# Mostrar el montaje personalizado\ncustom_montage.plot(show_names=True)\nfig = custom_montage.plot(kind=\"3d\", show_names=True, show=False)\nfig.gca().view_init(azim=70, elev=15)  # Ajustar la vista 3D","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.visualizations.git","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Topomaps","metadata":{}},{"cell_type":"code","source":"from gcpds.visualizations.topoplots import topoplot\n\n\ntrial = 150\nvec_topo_o = abs(X[trial,:]).mean(axis=-1)\nvec_topo_b = abs(Xrc[trial,:,:,:]).mean(axis=1)\n\n\nfig,ax = plt.subplots(1,6,figsize=(20,10))\ntopoplot(vec_topo_o, channels, contours=3, cmap='Reds', names=channels, sensors=False,ax=ax[0],show=False,vlim=(min(vec_topo_o), max(vec_topo_o)))\n\nfor b in range(f_bank.shape[0]):\n    vec_ = vec_topo_b[:,b]\n    topoplot(vec_, channels, contours=3, cmap='Reds', names=channels, sensors=False,ax=ax[b+1],show=False,vlim=(min(vec_), max(vec_)))\n    ax[b+1].set_title(ritmo[b])    \n\nax[0].set_title(f'EEG-suj={sbj}-trial={trial}')    \n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Ejercicio 7\n\nDiscuta","metadata":{}},{"cell_type":"markdown","source":"Tenemos seis mapas topográficos el primero correspondiente al EEG original y los siguientes cinco correspondientes a las señales filtradas en las bandas del banco f_bank, estos mapas representan la distribución espacial de la amplitud promedio en un trial específico, permitiendo identificar qué regiones corticales presentan mayor actividad en cada ritmo cerebral.\n\n\n## 1. EEG original\n\nEl mapa del EEG crudo muestra una mezcla simultánea de todas las bandas de frecuencia.\nSe observa potencia elevada en regiones frontales (Fp1–Fp2), característica de artefactos\noculares y actividad lenta. La distribución espacial no permite identificar claramente\nritmos neurales específicos debido a la superposición de componentes espectrales y ruido.\n\n## 2. Ritmo Delta (0.5-4 Hz)\n\nEl topoplot delta presenta actividad predominante en regiones frontales y prefrontales.\nEl ritmo delta está fuertemente influenciado por artefactos fisiológicos de baja frecuencia\n(parpadeos, movimientos, deriva de línea base). Su distribución carece de focalización\ncortical clara, siendo un ritmo poco informativo para tareas de imaginación motora.\n\n## 3. Ritmo Theta (4-8 Hz)\n\nEn theta se observa actividad moderada en zonas frontocentrales. Este ritmo se asocia a\nprocesos de atención, memoria y estados de somnolencia. Su expresión topográfica depende\ndel estado cognitivo del sujeto, pero no presenta un patrón motor marcado.\n\n## 4. Ritmo Alpha (8-13 Hz)\n\nEl ritmo alpha muestra una concentración marcada en regiones occipitales, consistente con\nla literatura neurofisiológica. Este patrón aumenta en estados de relajación con ojos \ncerrados y tiende a disminuir durante la ejecución o imaginación de tareas motoras. El \nmapa alpha permite identificar modulaciones del ritmo occipital y posibles efectos ERD/ERS.\n\n## 5. Ritmo Beta (13-32 Hz)\n\nEl topoplot beta es el más relevante para la imaginación motora. Se observa actividad \nfocalizada en las áreas sensoriomotoras (regiones C3 y C4). La topografía beta puede \npresentar asimetría según la mano imaginada, reflejando desincronización (ERD) en la \ncorteza motora contralateral. Esto lo convierte en un ritmo fundamental para sistemas BCI.\n\n## 6. Ritmo Gamma (32-100 Hz)\n\nEl mapa gamma presenta actividad distribuida en regiones temporales y zonas \nsusceptibles a contaminación muscular (EMG). El ritmo gamma en EEG de superficie tiene \nrelativamente bajo cociente señal–ruido y es altamente sensible a artefactos y ruido \neléctrico. Su patrón espacial suele ser menos estable que el de bandas más bajas.\n\n## Conclusiones\n\nLos mapas topográficos muestran que cada ritmo cerebral posee una distribución espacial \ncaracterística:\n\n- Delta y theta: actividad lenta de origen no específico, altamente influenciada por artefactos.  \n- Alpha: actividad occipital típica.  \n- Beta: activación sensoriomotora crucial para imaginación motora.  \n- Gamma: actividad rápida con alta susceptibilidad al ruido.\n\nLa comparación entre el EEG original y los mapas filtrados confirma que el banco de \nfiltros permite aislar correctamente los ritmos corticales y facilita el análisis espacial \nen tareas de BCI basadas en imaginación motora.\n","metadata":{}},{"cell_type":"markdown","source":"## Common Spatial Patterns\n\nConsulté qué son los Common Spatial Patterns (CSP) y su aplicación al procesado de señales EEG","metadata":{}},{"cell_type":"markdown","source":"# Common Spatial Patterns (CSP) y su aplicación al procesado de señales EEG\n\nLos Common Spatial Patterns (CSP) son un método de filtrado espacial \nsupervisado ampliamente utilizado en el procesado de señales EEG, especialmente en sistemas de Interfaces Cerebro-Computador (BCI) basados\nen tareas de imaginación motora. El objetivo de CSP es encontrar combinaciones lineales de los canales EEG que maximicen la separabilidad entre dos clases.\n\n**¿Qué hace CSP?**\n\nCSP busca filtros espaciales que generen nuevas proyecciones de la señal \ndonde:\n- una clase presenta \\textbf{máxima varianza}, y  \n- la otra clase presenta \\textbf{mínima varianza}.  \nLa varianza de una señal EEG es proporcional a su \\textbf{potencia}, por lo que \nCSP explota diferencias en la actividad cortical entre clases. En tareas de \nimaginación motora, por ejemplo, la potencia en las bandas mu y beta disminuye \nde manera diferencial entre regiones C3 y C4 según la mano imaginada. CSP \ncapta exactamente estas diferencias.\n\n**Interpretación neurofisiológica**\n\nCada filtro CSP produce un mapa espacial que representa pesos positivos y \nnegativos asociados a cada electrodo:\n- Pesos positivos: aumento relativo de actividad.  \n- Pesos negativos: disminución relativa.  \n\nLos mapas de CSP suelen resaltar:\n- la \\textbf{corteza sensoriomotora},  \n- patrones de lateralización (C3 vs. C4),  \n- zonas relevantes para eventos ERD/ERS.  \n\nEsto permite interpretar de manera fisiológica qué áreas discriminan mejor \nentre dos clases de movimiento imaginado.\n\n**Formulación matemática**\n\nSea una matriz de datos de EEG con C canales y T muestras:\n$$\nX_1 \\in \\mathbb{R}^{C \\times T}, \\qquad \nX_2 \\in \\mathbb{R}^{C \\times T}\n$$\ncorrespondientes a dos clases:\n\n1. Se calculan las matrices de covarianza normalizadas:\n$$\nR_1 = \\frac{X_1 X_1^\\top}{\\operatorname{trace}(X_1 X_1^\\top)}, \n\\qquad\nR_2 = \\frac{X_2 X_2^\\top}{\\operatorname{trace}(X_2 X_2^\\top)}.\n$$\n\n2. Se forma la matriz de covarianza compuesta:\n$$\nR = R_1 + R_2.\n$$\n\n3. Se realiza la descomposición espectral:\n$$\nR = U \\Lambda U^\\top.\n$$\n\n4. Se construye la matriz de blanqueamiento:\n$$\nP = \\Lambda^{-1/2} U^\\top.\n$$\n\n5. Se diagonaliza simultáneamente:\n$$\nS_1 = P R_1 P^\\top = B \\Lambda_1 B^\\top.\n$$\nLas columnas de B forman los filtros espaciales CSP.\nLos primeros filtros maximizan la varianza de la clase 1 y minimizan la de la clase 2. \nLos últimos filtros hacen lo contrario.\n\n**Extracción de características**\n\nTras aplicar los filtros:\n$$\nZ = W X,\n$$\n\nlas características se obtienen mediante la varianza logarítmica:\n$$\nf_i = \n\\log \n\\left( \n\\frac{\\operatorname{var}(Z_i)}\n{\\sum_j \\operatorname{var}(Z_j)} \n\\right).\n$$\n\nEstos vectores de características suelen emplearse junto a clasificadores como:\n- LDA,\n- SVM,\n- Random Forest.\n\n**Aplicación de CSP en BCI**\n\nCSP es uno de los métodos más utilizados en:\n- competiciones BCI,\n- análisis de imaginación motora (MI),\n- bases de datos como BCI Competition II/III/IV,\n- software especializado como MNE, BCI2000, OpenViBE.\n\nSu eficacia deriva de que los ritmos mu (8--13 Hz) y beta (13--32 Hz) presentan \nmodulaciones espaciales claras (ERD/ERS) durante MI, especialmente en las áreas \nmotoras contralaterales.\n\n**Ventajas**\n\n- Alta capacidad discriminativa para dos clases.  \n- Fácil de interpretar mediante topoplots.  \n- Computacionalmente eficiente.  \n- Excelente desempeño en MI.\n\n**Desventajas**\n\n- Sensible a ruido y artefactos (EOG, EMG).  \n- Requiere estabilidad en los electrodos.  \n- La versión estándar sólo maneja dos clases \n  (extensiones: One-vs-Rest, Multi-CSP, FBCSP).\n\n**Resumen**\n$$\n\\textbf{CSP} \\Rightarrow\n\\text{ filtros espaciales que maximizan diferencias de potencia entre clases}.\n$$\n\nEs un método fundamental para separar patrones de actividad cortical en \nimaginación motora y constituye una de las técnicas más importantes dentro \ndel preprocesamiento y extracción de características en BCI.\n","metadata":{}},{"cell_type":"code","source":"import mne\nfrom mne.decoding import CSP\n\n# Instancia del objeto CSP\nn_components = 2\ncsp = CSP(n_components=n_components, log= True, transform_into='average_power')\n# Ajuste y transformación de los datos\ncsp_data = csp.fit_transform(X.astype(np.float64), y)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"CSP Transformado Shape:\", csp_data.shape)\nplt.scatter(csp_data[:,0],csp_data[:,1],c=y)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#EEG original\nfig,ax = plt.subplots(1,n_components,figsize=(5,5))\nfor cc in range(n_components):\n    vec_ = np.abs(csp.filters_[cc])\n    topoplot(vec_, channels, contours=3, cmap='Reds', names=channels, sensors=False,ax=ax[cc],show=False,vlim=(min(vec_), max(vec_)))\n    ax[cc].set_title(f'CSP {cc+1}') \n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#lectura de datos\nsbj = 14\nX, y = load_GIGA(sbj=sbj, **load_args)\n\nf_bank = np.array([[0.5,4.],[4., 8.],[8.,13.],[13.,32.],[32.,100.]])\nvwt = np.array([[0.25, 1.75],[1.5,3],[2.75,4.25],[4,5.5],[5.25,6.75]]) #2.5 - 5 MI 0 - 7 trial completo\ntf_repr = TimeFrequencyRpr(sfreq = new_fs, f_bank = f_bank,vwt=vwt)\nX_ = np.squeeze(tf_repr.transform(X))\nX_.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# csp por ventanas y ritmos\n# Definir las dimensiones del arreglo\nritmos_ = f_bank.shape[0] \nventanas_ = vwt.shape[0]\nn_comp = 2\n# Inicializar el arreglo vacío con listas anidadas\ncsp_M = [[None for _ in range(ventanas_)] for _ in range(ritmos_)]\ncsp_filters_ = np.zeros((ritmos_,ventanas_,X_.shape[1],X_.shape[1])) #ritmos ventanas Ch\nXcsp_ = np.zeros((X_.shape[0],n_comp,ritmos_,ventanas_))\n\nfor i in range(ritmos_):\n    for j in range(ventanas_):\n        print(f'CSP ritmo {f_bank[i]} -- ventana {vwt[j]}...')\n        csp_M[i][j] =  CSP(n_components=n_comp, log= True, transform_into='average_power')\n        Xcsp_[:,:,i,j] = csp.fit_transform(X_[:,:,:,j,i].astype(np.float64), y)\n        csp_filters_[i,j,:] = np.abs(csp.filters_) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# graficar topomaps\nfig, ax = plt.subplots(ritmos_,ventanas_,figsize=(12,12))\n\nfor i in range(ritmos_):\n    for j in range(ventanas_):\n        vec_ = csp_filters_[i,j,0]\n        vec_ = vec_/max(vec_)\n        topoplot(vec_, channels, contours=3, cmap='Reds', names=None, sensors=False,ax=ax[i,j],show=False,vlim=(min(vec_), max(vec_)))\n    ax[i,0].set_ylabel(ritmo[i],fontsize=20)   \nfor j in range(ventanas_):\n     ax[0,j].set_title(f'{vwt[j,0]}--{vwt[j,1]} [s]',fontsize=15)\n    \nplt.subplots_adjust(hspace=-0.025,wspace=-0.025)    \nplt.show()      ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#scatters\nfig, ax = plt.subplots(ritmos_,ventanas_,figsize=(12,12))\n\nfor i in range(ritmos_):\n    for j in range(ventanas_):\n        ax[i,j].scatter(Xcsp_[:,0,i,j],Xcsp_[:,1,i,j],c=y)\n        ax[i,j].set_xticks([])\n        ax[i,j].set_yticks([])\n    ax[i,0].set_ylabel(ritmo[i],fontsize=20)   \nfor j in range(ventanas_):\n     ax[0,j].set_title(f'{vwt[j,0]}--{vwt[j,1]} [s]',fontsize=15)\n    \nplt.subplots_adjust(hspace=0.1,wspace=0.1)    \nplt.show()  ","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}